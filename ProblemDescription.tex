\section{Problem Description}
Eye-tracking and gaze estimation has a lot of applications, for example in enabling disabled people, and in particular people with Amyotrophic Lateral Sclerosis (ALS), the ability to type with and control devices using their eyes.

In this project we attempt to determine whether it is possible to perform gaze estimation using machine learning. Using machine learning for gaze estimation can be problematic, as images of faces (or eyes) are high-dimensional data, making learning complex and expensive. There are a few approaches to reducing the complexity: reducing the input space by example turning the image into grayscale, isolating the eye, and scaling the resulting image or by extracting features of the eye such as eye corners and the center of the pupil. 
In this project we attempt both approaches.